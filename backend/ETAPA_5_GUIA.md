# ğŸ¦ğŸ“° ETAPA 5: Sistema de Coleta de Dados (News + Twitter)

## ğŸ¯ O Que Foi Criado

Sistema completo de coleta automÃ¡tica de dados de crimes por RUA!

### ğŸ“¦ 4 Scripts Criados:

1. **`geocoding_service.py`** âœ…
   - Converte endereÃ§os em coordenadas (Google Maps)
   - Extrai endereÃ§os de textos com regex
   - Valida coordenadas por cidade

2. **`news_scraper.py`** âœ…
   - Raspa G1, Extra, O Globo
   - **GRATUITO** (sem custos)
   - 30-100 notÃ­cias/dia com endereÃ§os exatos

3. **`twitter_monitor.py`** âœ…
   - Monitora tweets sobre crimes
   - VersÃ£o gratuita (limitada)
   - 10-50 tweets/dia

4. **`orchestrator.py`** âœ…
   - Coordena tudo automaticamente
   - Roda News + Twitter em horÃ¡rios programados
   - Mostra estatÃ­sticas

---

## ğŸš€ COMO USAR

### Passo 1: Organizar Arquivos

```bash
cd ~/Documents/PROJETOS/painel_veiculos_sinesp/backend

# Criar pasta scripts (se nÃ£o existir)
mkdir -p scripts

# Copiar os 4 arquivos para scripts/:
# - geocoding_service.py
# - news_scraper.py
# - twitter_monitor.py
# - orchestrator.py
```

### Passo 2: Instalar DependÃªncias

```bash
# Ativar ambiente virtual
source .venv/bin/activate  # ou source ../.venv/bin/activate

# Instalar bibliotecas
pip install beautifulsoup4 lxml googlemaps tweepy schedule
```

### Passo 3: Configurar Google Maps API

VocÃª jÃ¡ tem a chave: (XXXX)

Ela jÃ¡ estÃ¡ configurada em `geocoding_service.py`! âœ…

### Passo 4: (Opcional) Configurar Twitter API

**IMPORTANTE:** Twitter API Ã© opcional! O sistema funciona sÃ³ com News Scraper.

Se quiser usar Twitter:

1. Acesse: https://developer.twitter.com/
2. Crie uma conta Developer (gratuita)
3. Crie um App
4. Copie o **Bearer Token**
5. Edite `twitter_monitor.py` e `orchestrator.py`:
   ```python
   TWITTER_BEARER_TOKEN = "seu_token_aqui"
   ```

**Limites do tier gratuito:**
- 10.000 tweets/mÃªs
- 100 tweets por requisiÃ§Ã£o
- Ideal para comeÃ§ar!

---

## ğŸ§ª TESTAR

### Teste 1: Geocoding Service

```bash
cd scripts
python geocoding_service.py
```

**SaÃ­da esperada:**
```
EndereÃ§o extraÃ­do: Rua Visconde de PirajÃ¡
Coordenadas: (-22.9839, -43.2058)
EndereÃ§o completo: {...}
Coordenadas vÃ¡lidas: True
```

### Teste 2: News Scraper

```bash
cd scripts
python news_scraper.py
```

**SaÃ­da esperada:**
```
==============================================================
  SafeDrive RJ - News Scraper
==============================================================

ğŸ“° Buscando notÃ­cias no G1 Rio...
âœ“ G1: 5 notÃ­cias encontradas

ğŸ“° Buscando notÃ­cias no Extra...
âœ“ Extra: 3 notÃ­cias encontradas

ğŸ“° Buscando notÃ­cias no O Globo...
âœ“ O Globo: 2 notÃ­cias encontradas

ğŸ’¾ Salvando 10 notÃ­cias no banco...
âœ“ 10 notÃ­cias salvas no banco

==============================================================
âœ“ Scraping concluÃ­do: 10 notÃ­cias salvas
==============================================================
```

### Teste 3: Twitter Monitor (se configurado)

```bash
cd scripts
python twitter_monitor.py
```

**SaÃ­da esperada:**
```
'assalto rio': 3 tweets
'roubo rio': 2 tweets

âœ“ 5 tweets salvos no banco
```

### Teste 4: Orchestrator (teste Ãºnico)

```bash
cd scripts
python orchestrator.py
```

Executa tudo de uma vez:
- News Scraper
- Twitter Monitor (se configurado)
- Mostra estatÃ­sticas

---

## ğŸ”„ RODAR AUTOMATICAMENTE

### OpÃ§Ã£o A: Modo ContÃ­nuo (Recomendado)

```bash
cd scripts
python orchestrator.py --continuous
```

**O que faz:**
- Roda News Scraper a cada 1 hora
- Roda Twitter a cada 15 minutos (se configurado)
- Mostra stats a cada 6 horas
- Fica rodando 24/7

**Para parar:** Ctrl+C

### OpÃ§Ã£o B: Cron Job (Background)

```bash
# Editar crontab
crontab -e

# Adicionar (rodar a cada 1 hora):
0 * * * * cd ~/Documents/PROJETOS/painel_veiculos_sinesp/backend/scripts && python orchestrator.py

# Ou a cada 6 horas:
0 */6 * * * cd ~/Documents/PROJETOS/painel_veiculos_sinesp/backend/scripts && python orchestrator.py
```

### OpÃ§Ã£o C: Deixar Rodando em Outra Aba

```bash
# Terminal 1: API
cd ~/Documents/PROJETOS/painel_veiculos_sinesp/backend
python -m uvicorn app.main:app --reload --port 8000

# Terminal 2: Orchestrator
cd ~/Documents/PROJETOS/painel_veiculos_sinesp/backend/scripts
python orchestrator.py --continuous
```

---

## ğŸ“Š VERIFICAR RESULTADOS

### No Banco de Dados

```bash
psql -U safedrive_user -d safedrive -h localhost
```

```sql
-- Ver total por fonte
SELECT source, COUNT(*) 
FROM crime_incidents 
GROUP BY source 
ORDER BY COUNT(*) DESC;

-- Ver notÃ­cias recentes
SELECT 
    source,
    crime_type,
    street_name,
    created_at
FROM crime_incidents
WHERE source IN ('G1', 'Extra', 'O Globo', 'Twitter')
ORDER BY created_at DESC
LIMIT 20;

-- Ver crimes COM endereÃ§o de rua
SELECT COUNT(*) 
FROM crime_incidents 
WHERE street_name IS NOT NULL;
```

### Na API

```bash
# Buscar crimes (deve incluir os novos)
curl "http://localhost:8000/api/crimes/nearby?lat=-22.9068&lng=-43.1729&radius=2000"

# Ver stats
curl "http://localhost:8000/api/crimes/stats?city=rio_de_janeiro"
```

---

## ğŸ“ˆ RESULTADOS ESPERADOS

### Depois de 1 hora:
- âœ… 10-20 notÃ­cias com endereÃ§os exatos
- âœ… 5-10 tweets (se Twitter configurado)
- âœ… Crimes por RUA especÃ­fica

### Depois de 24 horas:
- âœ… 100-200 notÃ­cias
- âœ… 50-100 tweets
- âœ… Cobertura de 50+ ruas diferentes

### Depois de 1 semana:
- âœ… 500-1000 novos crimes
- âœ… Dados por rua em vÃ¡rias regiÃµes
- âœ… PadrÃµes identificados por horÃ¡rio/local

### Depois de 1 mÃªs:
- âœ… 5.000+ crimes com endereÃ§os
- âœ… Cobertura completa do RJ
- âœ… + crowdsourcing de usuÃ¡rios do app
- âœ… Sistema totalmente funcional!

---

## ğŸ¯ COMO FUNCIONA

### News Scraper (Principal)

1. Acessa G1, Extra, O Globo
2. Busca notÃ­cias sobre crimes
3. Extrai o texto completo
4. Usa regex para encontrar endereÃ§os:
   - "Rua Visconde de PirajÃ¡"
   - "Avenida AtlÃ¢ntica, 1000"
   - "bairro Copacabana"
5. Geocodifica com Google Maps
6. Salva no banco com:
   - Coordenadas exatas
   - Nome da rua
   - Tipo de crime
   - Fonte verificada

### Twitter Monitor (Complementar)

1. Busca tweets com hashtags/keywords
2. Extrai endereÃ§os dos tweets
3. Geocodifica
4. Salva com confianÃ§a mÃ©dia (precisa validaÃ§Ã£o)

### Orchestrator (Coordenador)

1. Executa News Scraper de hora em hora
2. Executa Twitter a cada 15 minutos
3. Evita duplicatas (usa source_id Ãºnico)
4. Mostra estatÃ­sticas periodicamente

---

## ğŸ”§ CONFIGURAÃ‡ÃƒO AVANÃ‡ADA

### Adicionar Mais Sites

Edite `news_scraper.py`:

```python
def scrape_r7(self) -> List[Dict]:
    """Raspa notÃ­cias do R7"""
    # Implementar...
    pass
```

### Ajustar FrequÃªncia

Edite `orchestrator.py`:

```python
# Mudar de 1 hora para 30 minutos:
schedule.every(30).minutes.do(run_news_scraper)

# Mudar Twitter de 15 para 5 minutos:
schedule.every(5).minutes.do(run_twitter_monitor)
```

### Adicionar Cidades

Edite os scrapers para buscar "Volta Redonda" e "Pinheiral":

```python
coords = self.geocoder.geocode(address, "Volta Redonda, RJ")
```

---

## ğŸ› Troubleshooting

### Erro: "No module named 'googlemaps'"
```bash
pip install googlemaps beautifulsoup4 lxml tweepy schedule
```

### Erro: "API key not valid"
Verifique se a chave do Google Maps estÃ¡ correta em `geocoding_service.py`

### Erro: "Connection refused" (PostgreSQL)
```bash
brew services start postgresql@17
```

### Nenhuma notÃ­cia encontrada
Os sites mudaram o HTML. Verifique os seletores CSS nos mÃ©todos `scrape_*`

### Twitter nÃ£o funciona
Ã‰ opcional! Sistema funciona perfeitamente sÃ³ com News Scraper

### Poucos resultados
Normal no inÃ­cio. Deixe rodando 24h e verÃ¡ os dados acumularem

---

## ğŸ’¡ DICAS

1. **Deixe rodando 24/7**: Quanto mais tempo, mais dados
2. **Monitore os logs**: Veja o que estÃ¡ sendo encontrado
3. **Verifique duplicatas**: O sistema jÃ¡ remove automaticamente
4. **Twitter Ã© opcional**: News Scraper jÃ¡ dÃ¡ muitos dados
5. **Google Maps tem limites**: 
   - Gratuito: 40.000 requests/mÃªs
   - Suficiente para ~100 geocodificaÃ§Ãµes/dia

---

## ğŸ“š Fontes de Dados

### News (Principais):
- **G1 Rio**: https://g1.globo.com/rj/rio-de-janeiro/
- **Extra**: https://extra.globo.com/casos-de-policia/
- **O Globo**: https://oglobo.globo.com/rio/

### Twitter:
- Hashtags: #AssaltoRJ, #RouboRJ
- Keywords: "assalto rio", "roubo rio", "roubaram carro"

---

## âœ… CHECKLIST

Antes de deixar rodando 24/7:

- [ ] PostgreSQL rodando
- [ ] API FastAPI rodando
- [ ] Scripts na pasta `scripts/`
- [ ] DependÃªncias instaladas
- [ ] Google Maps API configurada
- [ ] Teste manual executado com sucesso
- [ ] Orchestrator funcionando
- [ ] Verificou dados no banco

---

**Pronto! Sistema de coleta automÃ¡tica funcionando! ğŸ‰**

Agora vocÃª terÃ¡ dados por RUA ESPECÃFICA em 24-48h! ğŸš€
